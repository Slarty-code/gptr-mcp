# Portainer Environment Variables for GPT Researcher MCP Server
# This file is used by Portainer when deploying from Git repository

# Ollama Configuration (matching your main GPT Researcher setup)
OPENAI_BASE_URL=http://host.docker.internal:11434/v1
OPENAI_API_KEY=ollama

# LLM Models (using your Ollama models)
FAST_LLM=ollama:gpt-oss:20b
SMART_LLM=ollama:gpt-oss:20b
STRATEGIC_LLM=ollama:gpt-oss:20b

# Embedding Model (using your Ollama embedding)
EMBEDDING=ollama:snowflake-arctic-embed2
EMBEDDING_PROVIDER=ollama

# Search Configuration
TAVILY_API_KEY=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

# GPT Researcher Configuration
# Maximum number of research iterations (2 for speed, 3+ for depth)
MAX_ITERATIONS=2

# Server Configuration
LOG_LEVEL=INFO
PORT=8000

# Optional: Add your other API keys if needed
# LANGCHAIN_API_KEY=
# ANTHROPIC_API_KEY=